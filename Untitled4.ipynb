{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPB2kqFdRUE14gTTTkh5br9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BastiCaa/prueba/blob/master/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOp3UvlvgFAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "myfile = drive.CreateFile({'id': '1ZLZA1oNBgVVN6hBwkW0eLUd4gCluCucL'})\n",
        "myfile.GetContentFile('dataset2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOnUZLCSx3Qv",
        "colab_type": "code",
        "outputId": "c29e3762-7ad7-4429-beff-7395f78d28f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import logging\n",
        "os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print (tf.__version__)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "tf.autograph.set_verbosity(2)\n",
        "\n",
        "datos2 = pd.read_csv(\"dataset2.csv\",sep=\",\")\n",
        "print(datos2.describe())\n",
        "#print(datos2)\n",
        "\n",
        "# Declare the inputs\n",
        "#x = datos2[[\"x\", \"y\"]]\n",
        "print(x)\n",
        "\n",
        "# Target\n",
        "y = datos2[[\"condition\"]]\n",
        "#print(y)\n",
        "\n",
        "# Division de la data de entrenamiento\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "# Escalar los datos\n",
        "escalar = StandardScaler()\n",
        "x_train = escalar.fit_transform(x_train)\n",
        "x_test = escalar.transform(x_test)\n",
        "print(tf.shape(x_train))\n",
        "print(tf.shape(y_train))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n",
            "                   x             y     condition\n",
            "count   81647.000000  8.164700e+04  81647.000000\n",
            "mean    -3086.777977  5.838926e+06      0.196713\n",
            "std     63564.806223  1.116634e+05      0.397516\n",
            "min   -115137.483721  5.641731e+06      0.000000\n",
            "25%    -57057.230344  5.740942e+06      0.000000\n",
            "50%     -3881.231445  5.841880e+06      0.000000\n",
            "75%     48810.641757  5.938679e+06      0.000000\n",
            "max    142472.558864  6.025505e+06      1.000000\n",
            "                   x             y\n",
            "0        7391.708670  5.898348e+06\n",
            "1       48438.984252  5.946210e+06\n",
            "2       -2768.592216  5.946243e+06\n",
            "3       41644.498119  5.915993e+06\n",
            "4       53467.799848  5.953068e+06\n",
            "...              ...           ...\n",
            "81642   41830.610412  6.005147e+06\n",
            "81643 -102288.468472  5.681305e+06\n",
            "81644   13339.987803  5.730445e+06\n",
            "81645   23010.374324  5.658347e+06\n",
            "81646   79450.815179  5.993709e+06\n",
            "\n",
            "[81647 rows x 2 columns]\n",
            "tf.Tensor([65317     2], shape=(2,), dtype=int32)\n",
            "tf.Tensor([65317     1], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1KQzLq2gcsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Model(object):\n",
        "    def __init__(self):\n",
        "    # In practice, these should be initialized to random values (for example, with `tf.random.normal`)\n",
        "        samples, features = (81647,2) #x.shape\n",
        "        hidden1_nodes = 9\n",
        "        hidden2_nodes = 2\n",
        "        hidden3_nodes = 1\n",
        "        self.theta1 = tf.Variable(tf.random.normal([features+1,hidden1_nodes], dtype= tf.float64) ,name = \"Theta1\")\n",
        "        self.theta2 = tf.Variable(tf.random.normal([hidden1_nodes+1,hidden2_nodes], dtype= tf.float64), name = \"Theta2\")\n",
        "        self.theta3 = tf.Variable(tf.random.normal([hidden2_nodes+1,hidden3_nodes], dtype= tf.float64), name = \"Theta3\")\n",
        "\n",
        "    def __call__(self, x_train): # Son metodos que vienen predifinidos desde el object.\n",
        "        # Estructura del dibujo del cuaderno.\n",
        "        bias1 = tf.constant(1, shape=(65317,1), dtype=tf.float64, name='bias1')\n",
        "        bias2 = tf.constant(1, shape=(65317,1), dtype=tf.float64, name='bias2')\n",
        "        bias3 = tf.constant(1, shape=(65317,1), dtype=tf.float64, name='bias3')\n",
        "        a0 = tf.concat([bias1,x_train],1, name='a0')\n",
        "        z1 = tf.matmul(a0,self.theta1, name='z1') # [4x2]\n",
        "        a1 = tf.concat([bias2,tf.sigmoid(z1)],1,name='a1')\n",
        "        z2 = tf.matmul(a1,self.theta2, name='z2')\n",
        "        a2 = tf.concat([bias3,tf.sigmoid(z2)],1,name=\"a2\")\n",
        "        z3 = tf.matmul(a2,self.theta3, name=\"z3\")\n",
        "        a3 = tf.sigmoid(z3, name='a3')\n",
        "        print('a3',tf.shape(a3))\n",
        "        return a3 # Respuesta, aqui ya predice\n",
        "\n",
        "def loss(ale_y, predicted_y): # Funcion de divergencia, Aqui esta la funcion Logistic_regression\n",
        "      print('predicted',tf.shape(predicted_y))\n",
        "      print('target',tf.shape(tf.shape(ale_y)))\n",
        "      return -tf.reduce_sum(ale_y*tf.math.log(predicted_y)+(1-ale_y)*tf.math.log(1-predicted_y),axis=0, name='Cost_function')\n",
        "\n",
        "def train(model, inputs, outputs, learning_rate): # Recibe todo, para entrenar el modelo.\n",
        "    with tf.GradientTape() as t:\n",
        "        current_loss = loss(outputs, model(inputs)) # El model con el call sabe predecir\n",
        "    dThe1, dThe2, dThe3 = t.gradient(current_loss, [model.theta1, model.theta2, model.theta3])\n",
        "    model.theta1.assign_sub(learning_rate * dThe1)\n",
        "    model.theta2.assign_sub(learning_rate * dThe2)\n",
        "    model.theta3.assign_sub(learning_rate * dThe3)\n",
        "    \n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"\n",
        "    Returns a custom learning rate that decreases as epochs progress.\n",
        "    \"\"\"\n",
        "    learning_rate = 0.2\n",
        "    if epoch > 3000:\n",
        "        learning_rate = 0.15\n",
        "    if epoch > 4000:\n",
        "        learning_rate = 0.1\n",
        "    if epoch > 4500:\n",
        "        learning_rate = 0.05\n",
        "    return learning_rate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiUs49JjiYHh",
        "colab_type": "code",
        "outputId": "9ff70616-1a3e-42d3-b166-9aae383189d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "\n",
        "model = Model() # Voy ajustando mis tetas en el proceso de aprendizaje\n",
        "theta1_hist, theta2_hist, theta3_hist= [], [], []\n",
        "for epoch in range(5000):\n",
        "    current_loss = loss(y_train, model(x_train))\n",
        "    learning_rate = lr_schedule(epoch)\n",
        "    train(model, x_train,y_train, learning_rate=learning_rate)\n",
        "    if epoch % 100 == 0:\n",
        "        theta1_hist.append(model.theta1.numpy())\n",
        "        theta2_hist.append(model.theta2.numpy())\n",
        "        theta3_hist.append(model.theta3.numpy())\n",
        "        print('Epoch %2d: learning_rate=%2.5f, loss=%2.5f' % (epoch, learning_rate, current_loss))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a3 tf.Tensor([65317     1], shape=(2,), dtype=int32)\n",
            "predicted tf.Tensor([65317     1], shape=(2,), dtype=int32)\n",
            "target tf.Tensor([2], shape=(1,), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-05beb208e0b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_entre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_entre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_entre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-9f0c0f2e6611>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(ale_y, predicted_y)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0male_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0male_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0male_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cost_function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Recibe todo, para entrenar el modelo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_frame_arith_method_with_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[0;34m(left, right, axis)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# GH17901\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 639\u001b[0;31m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m                 )\n\u001b[1;32m    641\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 1: given 65317"
          ]
        }
      ]
    }
  ]
}